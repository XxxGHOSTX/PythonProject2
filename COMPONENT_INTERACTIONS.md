# THALOS PRIME - COMPONENT INTERACTIONS

## Overview

This document details how components interact with each other, including database/persistence mechanisms, integration reports, import dependencies, and component lifecycle management.

---

## ðŸ”— Component Dependency Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HTML INTERFACES                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   thalos_    â”‚  â”‚   thalos_    â”‚  â”‚  thalos_prime_           â”‚  â”‚
â”‚  â”‚  celestial   â”‚  â”‚   coding_    â”‚  â”‚  primary_directive       â”‚  â”‚
â”‚  â”‚   .html      â”‚  â”‚  agent.html  â”‚  â”‚  .html                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                      â”‚
          â”‚ fetch()          â”‚ fetch()              â”‚ fetch()
          â–¼                  â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API SERVERS                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  biocomputing_   â”‚  â”‚   tpca_api_      â”‚  â”‚  THALOS_PRIME_  â”‚  â”‚
â”‚  â”‚  api_server.py   â”‚  â”‚   server.py      â”‚  â”‚  APP.py         â”‚  â”‚
â”‚  â”‚  (Port 5001)     â”‚  â”‚  (Port 5002)     â”‚  â”‚  (Port 8888)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ import               â”‚ import               â”‚ import
            â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CORE ENGINES                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  BIOCOMPUTING_   â”‚  â”‚  thalos_coding_  â”‚  â”‚  thalos_sbi_    â”‚  â”‚
â”‚  â”‚  CORE.py         â”‚  â”‚  agent_core.py   â”‚  â”‚  core_v6.py     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                      â”‚                      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                       â”‚
                       â–¼                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  thalos_database_â”‚    â”‚  autonomous_core â”‚
            â”‚  schema.py       â”‚    â”‚  .py             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“¦ Import Dependencies

### Core Import Chain

#### Level 1: Core Engines (No Dependencies)
```python
# BIOCOMPUTING_CORE.py
import json
import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime
import hashlib

# No internal imports - self-contained
```

```python
# thalos_sbi_core_v6.py
import numpy as np
import json
import time
import hashlib
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from enum import Enum
import sqlite3
import base64

# No internal imports - self-contained
```

```python
# thalos_coding_agent_core.py
import re
import json
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

# No internal imports - self-contained
```

#### Level 2: API Servers (Import Core Engines)
```python
# biocomputing_api_server.py
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
from datetime import datetime
import time
import threading
from functools import wraps
from typing import Dict, Any, Optional, Tuple

# Internal import with error handling
try:
    from BIOCOMPUTING_CORE import get_biocomputing_core, BiologicalResponse
    BIOCORE_AVAILABLE = True
except ImportError as e:
    logger.warning(f"BIOCOMPUTING_CORE not available: {e}")
    BIOCORE_AVAILABLE = False
```

```python
# tpca_api_server.py (current implementation excerpt)
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import logging
import os
from datetime import datetime

from thalos_coding_agent_core import ThalosCodingAgentCore, CodeRequest, GenerationMode
# Note: In the current implementation, TPCA core is imported directly.
# If this import fails, the server will fail to start rather than degrading gracefully.
```

```python
# THALOS_PRIME_APP.py
import sys
import os
from pathlib import Path
import json
import threading
import http.server
import socketserver
import logging

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

class ThalosPrimeRequestHandler(http.server.BaseHTTPRequestHandler):
    """Standalone HTTP server handler for THALOS PRIME."""

    def _send_json(self, payload, status_code=200):
        data = json.dumps(payload).encode("utf-8")
        self.send_response(status_code)
        self.send_header("Content-Type", "application/json")
        self.send_header("Content-Length", str(len(data)))
        self.end_headers()
        self.wfile.write(data)

    def do_GET(self):
        if self.path == "/health":
            self._send_json({"status": "ok", "component": "THALOS_PRIME_APP"})
        elif self.path == "/":
            self._send_json({"message": "THALOS PRIME http.server endpoint"})
        else:
            self._send_json({"error": "not found"}, status_code=404)


def run_server(host="0.0.0.0", port=8080):
    with socketserver.TCPServer((host, port), ThalosPrimeRequestHandler) as httpd:
        logger.info("THALOS_PRIME_APP http.server listening on %s:%d", host, port)
        httpd.serve_forever()


if __name__ == "__main__":
    run_server()
```

#### Level 3: Integration Layers
```python
# hyper_nextus_server.py
from flask import Flask, request, jsonify, render_template_string
from flask_cors import CORS
import logging
import json
from datetime import datetime

# Imports all three core engines
try:
    from BIOCOMPUTING_CORE import get_biocomputing_core
    BIOCORE_AVAILABLE = True
except ImportError:
    BIOCORE_AVAILABLE = False

try:
    from thalos_coding_agent_core import ThalosCodingAgentCore
    TPCA_AVAILABLE = True
except ImportError:
    TPCA_AVAILABLE = False

try:
    from unrestricted_core import UnrestrictedCore
    UNRESTRICTED_AVAILABLE = True
except ImportError:
    UNRESTRICTED_AVAILABLE = False
```

#### Level 4: Autonomous Systems
```python
# autonomous_core.py
import os
import time
import threading
import logging
from datetime import datetime

# Monitors all components
try:
    from BIOCOMPUTING_CORE import get_biocomputing_core
except ImportError:
    pass

try:
    from thalos_sbi_core_v6 import ThalosApplication
except ImportError:
    pass

# Self-healing logic
```

### Import Error Handling Pattern

**Standard Pattern**:
```python
# Module-level import with availability flag
try:
    from COMPONENT import ComponentClass
    COMPONENT_AVAILABLE = True
    logger.info("COMPONENT loaded successfully")
except ImportError as e:
    COMPONENT_AVAILABLE = False
    logger.warning(f"COMPONENT not available: {e}")
except Exception as e:
    COMPONENT_AVAILABLE = False
    logger.error(f"Error loading COMPONENT: {e}")

# Usage with graceful degradation
def use_component():
    if COMPONENT_AVAILABLE:
        try:
            result = ComponentClass.method()
            return result
        except Exception as e:
            logger.error(f"Component error: {e}")
            return fallback_result()
    else:
        logger.debug("Using fallback due to unavailable component")
        return fallback_result()
```

---

## ðŸ’¾ Database & Persistence

### Database Schema

**File**: `thalos_database_schema.py`

#### Table Relationships

```
system_config
    â”‚
    â””â”€â–º Configuration parameters for all components

sessions â—„â”€â”€â”€â”€â”¬â”€â”€â”€â”€ encryption_keys
              â”‚         (1:1 relationship)
              â”‚
              â”œâ”€â”€â”€â”€ context_memory
              â”‚         (1:many relationship)
              â”‚
              â””â”€â”€â”€â”€ interactions â—„â”€â”€â”€â”¬â”€â”€â”€â”€ confidence_scores
                        (1:many)     â”‚         (1:1 relationship)
                                     â”‚
                                     â””â”€â”€â”€â”€ reasoning_traces
                                               (1:many relationship)

model_parameters â—„â”€â”€â”€â”€ model_version_history
    (versioned storage)     (audit trail)

embedding_cache â—„â”€â”€â”€â”€ semantic_mappings
    (tokenâ†’vector)        (textâ†’vector)

intent_patterns â—„â”€â”€â”€â”€ Used by all query processing

performance_metrics â”€â”€â–º Collected from all components

security_log â”€â”€â–º All security events

audit_log â”€â”€â–º All system actions

error_log â”€â”€â–º All exceptions

feature_flags â”€â”€â–º Runtime toggles for all features
```

#### Key Tables

**1. system_config**
```sql
CREATE TABLE system_config (
    config_id INTEGER PRIMARY KEY AUTOINCREMENT,
    parameter_name TEXT NOT NULL UNIQUE,
    parameter_value TEXT NOT NULL,
    data_type TEXT NOT NULL CHECK(data_type IN ('string', 'integer', 'float', 'boolean', 'json')),
    description TEXT,
    is_encrypted BOOLEAN DEFAULT 0,
    last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    modified_by TEXT
);
```

**Purpose**: Store configuration for all components
**Used By**: All servers, core engines
**Example Data**:
```json
{
    "vocab_size": 65536,
    "embedding_dim": 768,
    "auto_reset_interval": 3600,
    "biocore_port": 5001,
    "tpca_port": 5002
}
```

**2. sessions**
```sql
CREATE TABLE sessions (
    session_id TEXT PRIMARY KEY,
    user_id TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_metadata JSON,
    is_active BOOLEAN DEFAULT 1,
    total_interactions INTEGER DEFAULT 0
);
```

**Purpose**: Track user sessions across all interfaces
**Used By**: All HTML interfaces, API servers
**Lifecycle**:
1. Created on first query from user
2. Updated on each interaction
3. Auto-expires after inactivity
4. Stores context for conversation continuity

**3. interactions**
```sql
CREATE TABLE interactions (
    interaction_id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    query_text TEXT NOT NULL,
    response_text TEXT NOT NULL,
    domain TEXT,
    query_tokens INTEGER,
    response_tokens INTEGER,
    processing_time_ms INTEGER,
    FOREIGN KEY (session_id) REFERENCES sessions(session_id)
);
```

**Purpose**: Log all query-response pairs
**Used By**: All API servers
**Analytics**: Processing time trends, domain distribution, token usage

**4. model_parameters**
```sql
CREATE TABLE model_parameters (
    parameter_id INTEGER PRIMARY KEY AUTOINCREMENT,
    model_version TEXT NOT NULL,
    parameter_name TEXT NOT NULL,
    parameter_data BLOB NOT NULL,
    is_encrypted BOOLEAN DEFAULT 1,
    encryption_algorithm TEXT DEFAULT 'AES-256-GCM',
    data_shape TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(model_version, parameter_name)
);
```

**Purpose**: Store neural network weights (encrypted)
**Used By**: `thalos_sbi_core_v6.py`
**Security**: AES-256-GCM encryption, per-session keys

**5. reasoning_traces**
```sql
CREATE TABLE reasoning_traces (
    trace_id INTEGER PRIMARY KEY AUTOINCREMENT,
    interaction_id INTEGER NOT NULL,
    step_number INTEGER NOT NULL,
    step_description TEXT NOT NULL,
    intermediate_result TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (interaction_id) REFERENCES interactions(interaction_id)
);
```

**Purpose**: Log multi-step reasoning process
**Used By**: BIOCOMPUTING_CORE (pattern recognition)
**Debugging**: Understand how conclusions were reached

#### Database Access Pattern

**Initialization**:
```python
import sqlite3
from pathlib import Path

class ThalosDatabase:
    def __init__(self, db_path: str = ".thalos_data/thalos.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(exist_ok=True, parents=True)
        self.conn = sqlite3.connect(str(self.db_path))
        self._initialize_schema()
    
    def _initialize_schema(self):
        """Create tables if they don't exist."""
        cursor = self.conn.cursor()
        
        # Execute schema SQL
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS system_config (
                -- schema here
            )
        ''')
        
        self.conn.commit()
```

**Transaction Pattern**:
```python
def save_interaction(self, session_id: str, query: str, response: str, domain: str):
    """Save query-response interaction."""
    cursor = self.conn.cursor()
    
    try:
        cursor.execute('''
            INSERT INTO interactions 
            (session_id, query_text, response_text, domain)
            VALUES (?, ?, ?, ?)
        ''', (session_id, query, response, domain))
        
        self.conn.commit()
        return cursor.lastrowid
        
    except sqlite3.Error as e:
        self.conn.rollback()
        logger.error(f"Database error: {e}")
        return None
```

**Query Pattern**:
```python
def get_session_history(self, session_id: str, limit: int = 10):
    """Retrieve recent interactions for session."""
    cursor = self.conn.cursor()
    
    cursor.execute('''
        SELECT query_text, response_text, domain, timestamp
        FROM interactions
        WHERE session_id = ?
        ORDER BY timestamp DESC
        LIMIT ?
    ''', (session_id, limit))
    
    return cursor.fetchall()
```

### File-Based Persistence

#### Integration Reports

**Files**: `integration_report_cycle_N.json` (N = 1-51)

**Generation**: Automated by `infinite_integration.py`

**Purpose**: Track system health evolution over development cycles

**Structure**:
```json
{
    "cycle": 50,
    "timestamp": "2026-02-08T00:20:24Z",
    "files_scanned": {
        "python": 23,
        "html": 4,
        "batch": 27,
        "markdown": 33
    },
    "missing_imports": [
        // List of unresolved imports
    ],
    "missing_files": [
        // List of referenced but missing files
    ],
    "missing_scripts": [
        // List of referenced but missing scripts
    ],
    "optimizations_needed": [
        // List of suggested optimizations
    ],
    "integration_status": {
        "biocore_import": true,
        "sbi_import": true,
        "coding_import": true,
        "unrestricted_import": true,
        "autonomous_core": true,
        "server_running": true
    },
    "total_fixes_applied": 0,
    "total_additions": 0
}
```

**Usage**:
```python
import json
from pathlib import Path

def load_integration_report(cycle: int) -> dict:
    """Load specific integration report."""
    report_path = Path(f"integration_report_cycle_{cycle}.json")
    
    if report_path.exists():
        with open(report_path, 'r') as f:
            return json.load(f)
    else:
        return None

def analyze_integration_trends():
    """Analyze trends across all reports."""
    reports = []
    for cycle in range(1, 52):
        report = load_integration_report(cycle)
        if report:
            reports.append(report)
    
    # Analyze trends
    python_files = [r['files_scanned']['python'] for r in reports]
    issues = [len(r['missing_imports']) + len(r['missing_files']) for r in reports]
    
    return {
        'file_growth': python_files,
        'issue_trend': issues,
        'current_health': reports[-1]['integration_status']
    }
```

**Why 51 Cycles?**: Represents iterative development/integration cycles

#### Log Files

**biocore_api.log**:
```
2026-02-08 00:20:24 [BIOCORE_API] INFO: Starting server on port 5001
2026-02-08 00:20:25 [BIOCORE_API] INFO: BIOCOMPUTING_CORE initialized
2026-02-08 00:20:30 [BIOCORE_API] INFO: Received query: "What is a black hole?"
2026-02-08 00:20:31 [BIOCORE_API] INFO: Response generated in 1234ms
2026-02-08 01:20:24 [BIOCORE_API] INFO: Auto-reset triggered: Time interval
```

**tpca_api.log**:
```
2026-02-08 00:21:00 [TPCA_API] INFO: Server started on port 5002
2026-02-08 00:21:05 [TPCA_API] INFO: Code generation request: Python function
2026-02-08 00:21:06 [TPCA_API] INFO: Generated 45 lines of code
```

**autonomous_core.log**:
```
2026-02-08 00:22:00 [AUTONOMOUS] INFO: Starting autonomous monitoring
2026-02-08 00:22:10 [AUTONOMOUS] INFO: System health check: All OK
2026-02-08 00:22:20 [AUTONOMOUS] WARNING: High memory usage detected
2026-02-08 00:22:21 [AUTONOMOUS] INFO: Triggered garbage collection
```

#### Cache Files

**Embedding Cache** (`.thalos_cache/embeddings.pkl`):
```python
import pickle
from pathlib import Path

def save_embedding_cache(embeddings: dict):
    """Save token embeddings to disk."""
    cache_path = Path(".thalos_cache/embeddings.pkl")
    cache_path.parent.mkdir(exist_ok=True)
    
    with open(cache_path, 'wb') as f:
        pickle.dump(embeddings, f)

def load_embedding_cache() -> dict:
    """Load token embeddings from disk."""
    cache_path = Path(".thalos_cache/embeddings.pkl")
    
    if cache_path.exists():
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    else:
        return {}
```

---

## ðŸ”„ Component Lifecycle

### Startup Sequence

**Phase 1: Environment Initialization**
```
1. Check Python installation
2. Create/activate virtual environment (.venv)
3. Install dependencies (requirements.txt)
4. Create data directories (.thalos_data, .thalos_cache, .thalos_logs)
5. Initialize logging
```

**Phase 2: Core Engine Initialization**
```
6. Load BIOCOMPUTING_CORE
   â”œâ”€ Initialize NeuralOrganoidMatrix (50,000 units)
   â”œâ”€ Load domain classifiers
   â””â”€ Set up auto-reset mechanism

7. Load Thalos SBI Core (if needed)
   â”œâ”€ Initialize tokenizer (65,536 vocab)
   â”œâ”€ Load transformer layers (24 layers)
   â””â”€ Connect to database

8. Load TPCA Core (if needed)
   â”œâ”€ Initialize expert system
   â”œâ”€ Load pattern library
   â””â”€ Set up code generation pipeline
```

**Phase 3: Server Startup**
```
9. Start BIOCORE API Server (port 5001)
   â”œâ”€ Initialize Flask app
   â”œâ”€ Enable CORS
   â”œâ”€ Register endpoints
   â”œâ”€ Start auto-reset thread
   â””â”€ Health check verification

10. Start TPCA API Server (port 5002)
    â”œâ”€ Initialize Flask app
    â”œâ”€ Load TPCA core
    â”œâ”€ Register endpoints
    â””â”€ Health check verification

11. Start HYPER-NEXTUS (port 5000, optional)
    â”œâ”€ Initialize integration layer
    â”œâ”€ Connect to all cores
    â”œâ”€ Register unified endpoints
    â””â”€ Health check verification
```

**Phase 4: Interface Launch**
```
12. Open HTML interfaces
    â”œâ”€ Launch browser windows
    â”œâ”€ Load JavaScript/CSS
    â”œâ”€ Initialize particle systems
    â”œâ”€ Test API connections
    â””â”€ Display ready state
```

**Phase 5: Autonomous Monitoring**
```
13. Start autonomous systems (background)
    â”œâ”€ Start autonomous_core.py monitoring
    â”œâ”€ Start perpetual_optimizer.py
    â”œâ”€ Start auto_enhancer.py
    â””â”€ Generate integration reports
```

### Runtime Interactions

**Query Processing Flow**:
```
[User Input] â†’ [HTML Interface]
                    â”‚
                    â”œâ”€ JavaScript: Capture input
                    â”œâ”€ Validation: Check empty/length
                    â””â”€ API Call: fetch() to server
                            â”‚
                            â–¼
                    [API Server] (Port 5001)
                            â”‚
                            â”œâ”€ Parse JSON request
                            â”œâ”€ Extract parameters
                            â”œâ”€ Check auto-reset conditions
                            â””â”€ Route to core engine
                                    â”‚
                                    â–¼
                            [Core Engine] (BIOCOMPUTING_CORE)
                                    â”‚
                                    â”œâ”€ Create NeuralQuery object
                                    â”œâ”€ Infer domain
                                    â”œâ”€ Pattern recognition
                                    â”œâ”€ Cross-domain synthesis
                                    â””â”€ Generate BiologicalResponse
                                            â”‚
                                            â–¼
                                    [Response Object]
                                            â”‚
                                            â”œâ”€ response_text
                                            â”œâ”€ confidence
                                            â”œâ”€ domain
                                            â”œâ”€ reasoning_trace
                                            â””â”€ metadata
                                                    â”‚
                                                    â–¼
                                            [Database Persistence]
                                                    â”‚
                                                    â”œâ”€ Save interaction
                                                    â”œâ”€ Update session
                                                    â”œâ”€ Log reasoning trace
                                                    â””â”€ Update metrics
                                                            â”‚
                                                            â–¼
                                                    [JSON Response]
                                                            â”‚
                                                            â””â”€â–º Back to HTML
                                                                    â”‚
                                                                    â””â”€ Display to user
```

### Shutdown Sequence

**Graceful Shutdown**:
```
1. Stop accepting new requests
2. Complete in-flight requests
3. Save pending data to database
4. Flush log buffers
5. Close database connections
6. Stop autonomous monitoring
7. Terminate server processes
8. Clean up temporary files
```

**Emergency Shutdown**:
```
1. Immediate process termination (Ctrl+C or taskkill)
2. Database auto-recovery on next start
3. Log files preserved
4. No data loss (transactions committed)
```

---

## ðŸ”€ Cross-Component Communication

### HTTP/JSON Protocol

**Request Format (Standard)**:
```json
{
    "query": "User query text",
    "session_id": "unique_session_identifier",
    "domain": "optional_domain_hint",
    "context": {
        "previous_queries": ["query1", "query2"],
        "user_preferences": {...},
        "mode": "detailed|concise"
    },
    "metadata": {
        "timestamp": "2026-02-08T00:20:24Z",
        "interface": "thalos_celestial",
        "version": "3.0"
    }
}
```

**Response Format (Standard)**:
```json
{
    "success": true,
    "response": "Generated response text",
    "confidence": 0.95,
    "domain": "astrophysics",
    "cross_domain_connections": ["quantum_mechanics", "cosmology"],
    "reasoning_trace": [
        "Step 1: Identified domain as astrophysics",
        "Step 2: Retrieved relevant patterns",
        "Step 3: Synthesized response"
    ],
    "metadata": {
        "timestamp": "2026-02-08T00:20:25Z",
        "processing_time_ms": 1234,
        "tokens_used": 150,
        "model_version": "v9.0"
    },
    "session_id": "unique_session_identifier"
}
```

**Error Format**:
```json
{
    "success": false,
    "error": "Error message",
    "error_type": "ValidationError|ProcessingError|SystemError",
    "details": "Detailed error information",
    "fallback_available": true,
    "metadata": {
        "timestamp": "2026-02-08T00:20:25Z"
    }
}
```

### Inter-Server Communication

**HYPER-NEXTUS Routing**:
```python
class HyperNextusRouter:
    """Routes requests to appropriate backend service."""
    
    def route_query(self, query: str, domain: Optional[str] = None):
        """Route query to best service."""
        
        # Try BIOCORE for general queries
        if domain in ['astrophysics', 'cosmology', 'physics']:
            try:
                return self.biocore_client.query(query)
            except Exception as e:
                logger.warning(f"BIOCORE failed: {e}, trying SBI")
        
        # Try SBI for complex reasoning
        if domain in ['algorithm_design', 'mathematics']:
            try:
                return self.sbi_client.query(query)
            except Exception as e:
                logger.warning(f"SBI failed: {e}, trying TPCA")
        
        # Try TPCA for code generation
        if 'code' in query.lower() or 'function' in query.lower():
            try:
                return self.tpca_client.generate(query)
            except Exception as e:
                logger.warning(f"TPCA failed: {e}, using fallback")
        
        # Fallback
        return self.generate_fallback(query)
```

### Event-Driven Notifications

**Auto-Reset Event**:
```python
# biocomputing_api_server.py
def notify_reset_event():
    """Notify all components of reset."""
    
    event = {
        'type': 'reset',
        'component': 'BIOCOMPUTING_CORE',
        'timestamp': datetime.now().isoformat(),
        'reason': 'Time-based auto-reset'
    }
    
    # Log to database
    db.save_event(event)
    
    # Notify monitoring systems
    if AUTONOMOUS_CORE_AVAILABLE:
        autonomous_core.handle_event(event)
    
    # Broadcast to active sessions
    for session in active_sessions:
        session.notify('system_reset', event)
```

---

## ðŸ“Š Integration Monitoring

### Health Checks

**Endpoint Pattern**:
```python
@app.route('/api/health', methods=['GET'])
def health_check():
    """Comprehensive health check."""
    
    health = {
        'status': 'healthy',
        'component': 'BIOCORE_API',
        'version': '9.0',
        'uptime_seconds': time.time() - start_time,
        'checks': {
            'core_loaded': BIOCORE_AVAILABLE,
            'database_connected': db.is_connected(),
            'memory_ok': check_memory_usage(),
            'cpu_ok': check_cpu_usage()
        },
        'metrics': {
            'total_requests': request_counter,
            'error_count': error_counter,
            'average_response_time_ms': calculate_avg_response_time()
        },
        'timestamp': datetime.now().isoformat()
    }
    
    # Overall status
    if not all(health['checks'].values()):
        health['status'] = 'degraded'
    
    status_code = 200 if health['status'] == 'healthy' else 503
    return jsonify(health), status_code
```

### Integration Reports

**Generated By**: `infinite_integration.py`

**Frequency**: Every 100 file changes or daily

**Process**:
```python
import ast
import os
from pathlib import Path

def scan_integration_health():
    """Scan all Python files for integration issues."""
    
    report = {
        'cycle': get_next_cycle_number(),
        'timestamp': datetime.now().isoformat(),
        'files_scanned': {'python': 0, 'html': 0, 'batch': 0},
        'missing_imports': [],
        'missing_files': [],
        'integration_status': {}
    }
    
    # Scan Python files
    for py_file in Path('.').rglob('*.py'):
        report['files_scanned']['python'] += 1
        
        try:
            with open(py_file, 'r', encoding='utf-8') as f:
                tree = ast.parse(f.read())
            
            # Check imports
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        if not module_exists(alias.name):
                            report['missing_imports'].append({
                                'file': str(py_file),
                                'import': alias.name
                            })
                
                elif isinstance(node, ast.ImportFrom):
                    if not module_exists(node.module):
                        report['missing_imports'].append({
                            'file': str(py_file),
                            'import': node.module
                        })
        
        except SyntaxError as e:
            report['syntax_errors'].append({
                'file': str(py_file),
                'error': str(e)
            })
    
    # Test critical imports
    report['integration_status'] = {
        'biocore_import': test_import('BIOCOMPUTING_CORE'),
        'sbi_import': test_import('thalos_sbi_core_v6'),
        'coding_import': test_import('thalos_coding_agent_core'),
        'autonomous_core': test_import('autonomous_core')
    }
    
    # Save report
    report_path = Path(f"integration_report_cycle_{report['cycle']}.json")
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    return report
```

---

## ðŸŽ¯ Best Practices

### Component Communication

1. **Always use try-except for imports**
```python
try:
    from component import Class
    AVAILABLE = True
except ImportError:
    AVAILABLE = False
```

2. **Always check availability before use**
```python
if COMPONENT_AVAILABLE:
    result = component.method()
else:
    result = fallback()
```

3. **Always provide fallbacks**
```python
try:
    return online_method()
except:
    return offline_fallback()
```

4. **Always log errors, don't raise**
```python
try:
    risky_operation()
except Exception as e:
    logger.error(f"Error: {e}")
    return safe_default
```

### Database Usage

1. **Always use transactions**
```python
try:
    cursor.execute(query, params)
    conn.commit()
except:
    conn.rollback()
    raise
```

2. **Always close connections**
```python
try:
    conn = sqlite3.connect(db_path)
    # ... operations ...
finally:
    conn.close()
```

3. **Always validate input**
```python
def save_interaction(query: str, ...):
    if not query or len(query) > 10000:
        raise ValueError("Invalid query")
    # ... save ...
```

### Integration Monitoring

1. **Always implement health checks**
2. **Always log significant events**
3. **Always track metrics**
4. **Always provide status endpoints**

---

## ðŸ“š Related Documentation

- `SYSTEM_ARCHITECTURE.md` - System architecture overview
- `DEVELOPMENT_GUIDE.md` - Development workflows
- `TESTING_STRATEGY.md` - Testing approaches
- `DEPLOYMENT_README.md` - Deployment guide

---

**Document Version**: 1.0  
**Last Updated**: 2026-02-08  
**System Version**: THALOS PRIME v9.0
